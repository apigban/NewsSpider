import requests
from lxml import html
import log.log as log


def proxyScraper(htmlobject):
    proxyIP = [item for item in tree.xpath('//table/tbody/tr/td[1]/text()')]
    proxyPort = [item for item in tree.xpath('//table/tbody/tr/td[2]/text()')]
    proxyCountry = [item for item in tree.xpath('//table/tbody/tr/td[4]/text()')]
    proxyType = [item for item in tree.xpath('//table/tbody/tr/td[5]/text()')]
    proxyHTTPS = [item for item in tree.xpath('//table/tbody/tr/td[7]/text()')]
    proxyDiscovered = [item for item in tree.xpath('//table/tbody/tr/td[8]/text()')]

    proxyDict = {key: value for key, *value in
                 zip(proxyCountry, proxyIP, proxyPort, proxyType, proxyHTTPS, proxyDiscovered)}
    print(proxyDict)
    proxyLog.info(f'Stats: {len(proxyDict)} identified.')

    return proxyDict


if __name__ == '__main__':
    proxyLog = log.get_logger(__name__)
    proxyLog.info(f'Stats: identified.')
    uri = 'https://free-proxy-list.net/'

    headers = {
        'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_11_5) AppleWebKit/537.36 (KHTML, like Gecko) Cafari/537.36'}

    pageContent = requests.get(url=uri, headers=headers, timeout=10)

    tree = html.fromstring(pageContent.content)

    proxyScraper(tree)
